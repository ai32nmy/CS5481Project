# Agentic RAG Configuration

# Embedding Configuration
embeddings:
  provider: "huggingface"  # Options: "openai", "gemini", "huggingface"
  huggingface_model: "sentence-transformers/all-MiniLM-L6-v2"  # For HuggingFace (local)
  # model: "models/embedding-001"  # For Gemini
  # openai_model: "text-embedding-3-small"  # For OpenAI

# Vector Database Configuration
vector_db:
  provider: "chroma"
  persist_directory: "./chroma_db"
  collection_name: "knowledge_base"

# Chunking Configuration
chunking:
  chunk_size: 1000
  chunk_overlap: 200
  separators: ["\n\n", "\n", " ", ""]

# Retrieval Configuration
retrieval:
  top_k: 4
  search_type: "similarity"  # Options: "similarity", "mmr"
  score_threshold: 0.7

# LLM Configuration
llm:
  provider: "ollama"  # Options: "openai", "gemini", "ollama"
  ollama_model: "gemma3:12b"  # For Ollama (local)
  ollama_base_url: "http://localhost:11434"  # Default Ollama URL
  temperature: 0.1
  max_tokens: 10000
  # model: "gemini-2.0-flash"  # For Gemini
  # openai_model: "gpt-4o-mini"  # For OpenAI

# Agent Configuration
agent:
  max_iterations: 5
  verbose: true
  agent_type: "react"  # Options: "openai-tools", "react" (use "react" for Gemini)

# Data Sources
data_sources:
  documents_directory: "./documents"
  supported_formats: ["txt", "pdf", "md", "docx"]
